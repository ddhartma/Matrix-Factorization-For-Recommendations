{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys # can use sys to take command line arguments\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class Recommender():\n",
    "    '''\n",
    "    What is this class all about - write a really good doc string here\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        what do we need to start out our recommender system\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def read_dataset(self, movies_path='./movies_clean.csv', reviews_path='./train_data.csv'):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movies_path - (string) file path to the movies, default='./movies_clean.csv'\n",
    "            reviews_path - (string) file path to the reviews, default='./train_data.csv'\n",
    "        \n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            movies - (dataframe) movie dataframe\n",
    "            reviews - (dataframe) review dataframe\n",
    "        '''\n",
    "        \n",
    "        # Read in the datasets\n",
    "        movies = pd.read_csv(movies_path)\n",
    "        reviews = pd.read_csv(reviews_path)\n",
    "        \n",
    "        del movies['Unnamed: 0']\n",
    "        del reviews['Unnamed: 0']\n",
    "        \n",
    "        print('movies')\n",
    "        print(movies.head())\n",
    "        print(movies.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        print('reviews')\n",
    "        print(reviews.head())\n",
    "        print(reviews.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        return movies, reviews\n",
    "        \n",
    "    def create_train_test(reviews, order_by, train_size_prct=0.8):\n",
    "        '''    \n",
    "        INPUTS:\n",
    "        ------------\n",
    "            reviews - (pandas df) dataframe to split into train and test\n",
    "            order_by - (string) column name to sort by\n",
    "            train_size_prct - (float) - percentage of data used for training, default=0.8\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            training_df -  (pandas df) dataframe of the training set\n",
    "            validation_df - (pandas df) dataframe of the test set\n",
    "        '''\n",
    "\n",
    "        # Define the train and test data size via train_size_prct\n",
    "        training_size = int(reviews.shape[0] * train_size_prct)\n",
    "        testing_size = reviews.shape[0] - training_size\n",
    "        \n",
    "        # Sort the reviews by date before splitting\n",
    "        # use old data for training, new data for validation\n",
    "        reviews_new = reviews.sort_values(order_by)\n",
    "        training_df = reviews_new.head(training_size)\n",
    "        validation_df = reviews_new.iloc[training_size:training_size+testing_size]\n",
    "\n",
    "        print('reviews_new')\n",
    "        print(reviews_new.head())\n",
    "        print(reviews_new.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        print('training_df')\n",
    "        print(training_df.head())\n",
    "        print(training_df.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        print('validation_df')\n",
    "        print(validation_df.head())\n",
    "        print(validation_df.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "    \n",
    "        return training_df, validation_df\n",
    "\n",
    "    def fit(self,\n",
    "            movies_path - (string) file path to the movies, default='./movies_clean.csv',\n",
    "            reviews_path - (string) file path to the reviews, default='./train_data.csv'\n",
    "            order_by='date',\n",
    "            train_size_prct=0.8,\n",
    "            latent_features=15, \n",
    "            learning_rate=0.005, \n",
    "            iters=10):\n",
    "        \n",
    "        ''' Fit the recommender engine to the dataset and\n",
    "            save the results to pull from when you need to make predictions\n",
    "        \n",
    "        INPUTS:\n",
    "        ------------\n",
    "            order_by - (string) column name to sort by\n",
    "            train_size_prct - (float) - percentage of data used for training, default=0.8\n",
    "            latent_features - (int) the number of latent features used, default=15, \n",
    "            learning_rate - (float) the learning rate, default=0.005\n",
    "            iters - (int) the number of iterations, default=10\n",
    "            \n",
    "        OUTPUTS:\n",
    "        -------------\n",
    "            user_mat - (numpy array) a user by latent feature matrix\n",
    "            movie_mat - (numpy array) a latent feature by movie matrix\n",
    "        \n",
    "        '''\n",
    "        # Read in movie and review DataFrames\n",
    "        movies, reviews = self.read_dataset(movies_path,reviews_path)\n",
    "        \n",
    "        # Hyperparameters: Number of latent features, lr, epochs\n",
    "        latent_features = latent_features\n",
    "        learning_rate = learning_rate\n",
    "        iters = iters\n",
    "        \n",
    "        training_df, validation_df = self.create_train_test(reviews, order_by, train_size_prct)\n",
    "        \n",
    "        # Create user-by-item matrix as np array\n",
    "        train_user_item = training_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "        train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "        ratings_mat = np.array(train_data_df)\n",
    "        self.ratings_mat = ratings_mat\n",
    "              \n",
    "        print('user-by-item matrix')\n",
    "        print(ratings_mat)\n",
    "        print(ratings_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        # Number of users and movies in the user-by-item matrix \n",
    "        self.n_users = ratings_mat.shape[0]\n",
    "        self.n_movies = ratings_mat.shape[1]\n",
    "        self.num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "        \n",
    "        print('number of users: ', self.n_users)\n",
    "        print('number of movies: ', self.n_movies)   \n",
    "        print('number of non nan ratings: ', self.num_ratings)      \n",
    "\n",
    "        # Initialize the user and movie matrices with random values\n",
    "        user_mat = np.random.rand(self.n_users, latent_features)\n",
    "        movie_mat = np.random.rand(latent_features, self.n_movies)\n",
    "\n",
    "        print('U matrix (users) before training') \n",
    "        print(user_mat)\n",
    "        print(user_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        print('Vt matrix (movies) before training') \n",
    "        print(movie_mat)\n",
    "        print(movie_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        # Initialize sse at 0 for first iteration\n",
    "        sse_accum = 0\n",
    "\n",
    "        # keep track of iteration and MSE\n",
    "        print(\"Optimizaiton Statistics\")\n",
    "        print(\"Iterations | Mean Squared Error \")\n",
    "\n",
    "        # for each iteration\n",
    "        for iteration in range(iters):\n",
    "\n",
    "            # update our sse\n",
    "            old_sse = sse_accum\n",
    "            sse_accum = 0\n",
    "\n",
    "            # For each user-movie pair\n",
    "            for i in range(self.n_users):\n",
    "                for j in range(self.n_movies):\n",
    "\n",
    "                    # if the rating exists\n",
    "                    if ratings_mat[i, j] > 0:\n",
    "\n",
    "                        # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                        diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "\n",
    "                        # Keep track of the sum of squared errors for the matrix\n",
    "                        sse_accum += diff**2\n",
    "\n",
    "                        # update the values in each matrix in the direction of the gradient\n",
    "                        for k in range(latent_features):\n",
    "                            user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                            movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "                           \n",
    "            # print results\n",
    "            print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / self.num_ratings))\n",
    "            \n",
    "        # Validation\n",
    "        print('Start validation ...')\n",
    "        rmse, perc_rated, actual_v_pred, preds, acts = self.validation_comparison(self, validation_df, user_mat=user_mat, movie_mat=movie_mat)\n",
    "        print('rmse: ', rmse)\n",
    "        print('perc_rated: ', perc_rated)\n",
    "        print('actual_v_pred: ', actual_v_pred)\n",
    "        \n",
    "        self.plot_validation_results(rmse, perc_rated, actual_v_pred, preds, acts)\n",
    "        \n",
    "        print(' ')\n",
    "        print('Saving user-by-item matrix as pickle ...')\n",
    "        with open('ratings_mat.pkl','wb') as f:\n",
    "            pickle.dump(ratings_mat, f)\n",
    "        print('...done')\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        print(' ')\n",
    "        print('Saving user_mat as pickle ...')\n",
    "        with open('user_mat.pkl','wb') as f:\n",
    "            pickle.dump(user_mat, f)\n",
    "        print('...done')\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "            \n",
    "        print(' ')\n",
    "        print('Saving movie_mat as pickle ...')\n",
    "        with open('movie_mat.pkl','wb') as f:\n",
    "            pickle.dump(movie_mat, f)\n",
    "        print('...done')\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "                  \n",
    "        return user_mat, movie_mat, ratings_mat\n",
    "    \n",
    "    \n",
    "    def validation_comparison(self, val_df, user_mat=user_mat, movie_mat=movie_mat):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            val_df - the validation dataset created in the third cell above\n",
    "            user_mat - U matrix in FunkSVD\n",
    "            movie_mat - V matrix in FunkSVD\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            rmse - RMSE of how far off each value is from it's predicted value\n",
    "            perc_rated - percent of predictions out of all possible that could be rated\n",
    "            actual_v_pred - a 10 x 10 grid with counts for actual vs predicted values\n",
    "        '''\n",
    "\n",
    "        val_users = np.array(val_df['user_id'])\n",
    "        val_movies = np.array(val_df['movie_id'])\n",
    "        val_ratings = np.array(val_df['rating'])\n",
    "\n",
    "        sse = 0\n",
    "        num_rated = 0\n",
    "        preds, acts = [], []\n",
    "        actual_v_pred = np.zeros((10,10))\n",
    "        for idx in range(len(val_users)):\n",
    "            try:\n",
    "                pred = predict_rating(user_mat, movie_mat, val_users[idx], val_movies[idx])\n",
    "                sse += (val_ratings[idx] - pred)**2\n",
    "                num_rated+=1\n",
    "                preds.append(pred)\n",
    "                acts.append(val_ratings[idx])\n",
    "                actual_v_pred[11-int(val_ratings[idx]-1), int(round(pred)-1)]+=1\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        rmse = np.sqrt(sse/num_rated)\n",
    "        perc_rated = num_rated/len(val_users)\n",
    "        return rmse, perc_rated, actual_v_pred, preds, acts\n",
    "    \n",
    "    def plot_validation_results(self, rmse, perc_rated, actual_v_pred, preds, acts):\n",
    "        # How well did we do?\n",
    "        print(rmse, perc_rated)\n",
    "        sns.heatmap(actual_v_pred);\n",
    "        plt.xticks(np.arange(10), np.arange(1,11));\n",
    "        plt.yticks(np.arange(10), np.arange(1,11));\n",
    "        plt.xlabel(\"Predicted Values\");\n",
    "        plt.ylabel(\"Actual Values\");\n",
    "        plt.title(\"Actual vs. Predicted Values\");\n",
    "\n",
    "    def load_matrices(self, ratings_mat_path='ratings_mat.pkl', user_mat_path='user_mat.pkl', movie_mat_path='movie_mat.pkl'):\n",
    "        \n",
    "        with open(user_mat_path,'rb') as f:\n",
    "            user_mat = pickle.load(f)\n",
    "        print('Shape of user_mat')\n",
    "        print(user_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        with open(user_mat_path,'rb') as f:\n",
    "            user_mat = pickle.load(f)\n",
    "        print('Shape of user_mat')\n",
    "        print(user_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        \n",
    "        with open(movie_mat_path,'rb') as f:\n",
    "            movie_mat = pickle.load(f)\n",
    "        print('Shape of user_mat')\n",
    "        print(movie_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        return user_mat, movie_mat\n",
    "        \n",
    "        \n",
    "    def predict_rating(self):\n",
    "        ''' makes predictions of a rating for a user on a movie-user combo\n",
    "        \n",
    "        INPUTS:\n",
    "        ------------\n",
    "            user_matrix - user by latent factor matrix\n",
    "            movie_matrix - latent factor by movie matrix\n",
    "            user_id - the user_id from the reviews df\n",
    "            movie_id - the movie_id according the movies df\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "        '''\n",
    "        user_mat, movie_mat, ratings_mat = self.load_matrices()\n",
    "\n",
    "        # Create series of users and movies in the right order\n",
    "        user_ids_series = np.array(ratings_mat.index)\n",
    "        movie_ids_series = np.array(ratings_mat.columns)\n",
    "\n",
    "        # User row and Movie Column\n",
    "        user_row = np.where(user_ids_series == user_id)[0][0]\n",
    "        movie_col = np.where(movie_ids_series == movie_id)[0][0]\n",
    "\n",
    "        # Take dot product of that row and column in U and V to make prediction\n",
    "        pred = np.dot(user_matrix[user_row, :], movie_matrix[:, movie_col])\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    def find_similar_movies(self, movie_id):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movie_id - a movie_id \n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            similar_movies - an array of the most similar movies by title\n",
    "        '''\n",
    "\n",
    "        # find the row of each movie id\n",
    "        movie_idx = np.where(movies['movie_id'] == movie_id)[0][0]\n",
    "\n",
    "        # find the most similar movie indices - to start I said they need to be the same for all content\n",
    "        similar_idxs = np.where(dot_prod_movies[movie_idx] == np.max(dot_prod_movies[movie_idx]))[0]\n",
    "\n",
    "        # pull the movie titles based on the indices\n",
    "        similar_movies = np.array(movies.iloc[similar_idxs, ]['movie'])\n",
    "\n",
    "        return similar_movies\n",
    "    \n",
    "    def get_movie_names(self, movie_ids):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movie_ids - a list of movie_ids\n",
    "\n",
    "        OUTPUT:\n",
    "        ------------\n",
    "            movies - a list of movie names associated with the movie_ids\n",
    "        '''\n",
    "\n",
    "        movie_lst = list(movies[movies['movie_id'].isin(movie_ids)]['movie'])\n",
    "\n",
    "        return movie_lst\n",
    "    \n",
    "   \n",
    "    \n",
    "    def create_ranked_df(self, movies, reviews):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movies - the movies dataframe\n",
    "            reviews - the reviews dataframe\n",
    "\n",
    "        OUTPUT:\n",
    "        ------------\n",
    "            ranked_movies - a dataframe with movies that are sorted by highest avg rating, more reviews, \n",
    "                        then time, and must have more than 4 ratings\n",
    "        '''\n",
    "\n",
    "        # Pull the average ratings and number of ratings for each movie\n",
    "        movie_ratings = reviews.groupby('movie_id')['rating']\n",
    "        avg_ratings = movie_ratings.mean()\n",
    "        num_ratings = movie_ratings.count()\n",
    "        last_rating = pd.DataFrame(reviews.groupby('movie_id').max()['date'])\n",
    "        last_rating.columns = ['last_rating']\n",
    "\n",
    "        # Add Dates\n",
    "        rating_count_df = pd.DataFrame({'avg_rating': avg_ratings, 'num_ratings': num_ratings})\n",
    "        rating_count_df = rating_count_df.join(last_rating)\n",
    "\n",
    "        # merge with the movies dataset\n",
    "        movie_recs = movies.set_index('movie_id').join(rating_count_df)\n",
    "\n",
    "        # sort by top avg rating and number of ratings\n",
    "        ranked_movies = movie_recs.sort_values(['avg_rating', 'num_ratings', 'last_rating'], ascending=False)\n",
    "\n",
    "        # for edge cases - subset the movie list to those with only 5 or more reviews\n",
    "        ranked_movies = ranked_movies[ranked_movies['num_ratings'] > 4]\n",
    "\n",
    "        return ranked_movies\n",
    "    \n",
    "\n",
    "    def popular_recommendations(self, user_id, n_top, ranked_movies):\n",
    "        '''\n",
    "        INPUT:\n",
    "        ------------\n",
    "            user_id - the user_id (str) of the individual you are making recommendations for\n",
    "            n_top - an integer of the number recommendations you want back\n",
    "            ranked_movies - a pandas dataframe of the already ranked movies based on avg rating, count, and time\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            top_movies - a list of the n_top recommended movies by movie title in order best to worst\n",
    "        '''\n",
    "\n",
    "        top_movies = list(ranked_movies['movie'][:n_top])\n",
    "\n",
    "        return top_movies\n",
    "\n",
    "    \n",
    "        \n",
    "    def start_prediction(self):\n",
    "        user_mat, movie_mat = self.load_matrices()\n",
    "   \n",
    "\n",
    "    def make_recs(self, _id, _id_type='movie', train_data=train_data_df, train_df=train_df, movies=movies, rec_num=5, user_mat=user_mat):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            _id - either a user or movie id (int)\n",
    "            _id_type - \"movie\" or \"user\" (str)\n",
    "            train_data - dataframe of data as user-movie matrix\n",
    "            train_df - dataframe of training data reviews\n",
    "            movies - movies df\n",
    "            rec_num - number of recommendations to return (int)\n",
    "            user_mat - the U matrix of matrix factorization\n",
    "            movie_mat - the V matrix of matrix factorization\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            recs - (array) a list or numpy array of recommended movies like the \n",
    "                    given movie, or recs for a user_id given\n",
    "        '''\n",
    "\n",
    "        # if the user is available from the matrix factorization data, \n",
    "        # I will use this and rank movies based on the predicted values\n",
    "        # For use with user indexing\n",
    "        val_users = train_data_df.index\n",
    "        rec_ids = create_ranked_df(movies, train_df)\n",
    "\n",
    "        if _id_type == 'user':\n",
    "            if _id in train_data.index:\n",
    "                # Get the index of which row the user is in for use in U matrix\n",
    "                idx = np.where(val_users == _id)[0][0]\n",
    "\n",
    "                # take the dot product of that row and the V matrix\n",
    "                preds = np.dot(user_mat[idx,:],movie_mat)\n",
    "\n",
    "                # pull the top movies according to the prediction\n",
    "                indices = preds.argsort()[-rec_num:][::-1] #indices\n",
    "                rec_ids = train_data_df.columns[indices]\n",
    "                rec_names = get_movie_names(rec_ids)\n",
    "\n",
    "            else:\n",
    "                # if we don't have this user, give just top ratings back\n",
    "                rec_names = popular_recommendations(_id, rec_num, ranked_movies)\n",
    "\n",
    "        # Find similar movies if it is a movie that is passed\n",
    "        else:\n",
    "            rec_ids = find_similar_movies(_id)\n",
    "            rec_names = get_movie_names(rec_ids)\n",
    "\n",
    "        return rec_ids, rec_names\n",
    "    \n",
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # test different parts to make sure it works\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender()\n",
    "rec.fit()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
