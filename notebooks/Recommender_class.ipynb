{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys # can use sys to take command line arguments\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender():\n",
    "    '''\n",
    "    What is this class all about - write a really good doc string here\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        what do we need to start out our recommender system\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def read_dataset(self, movies_path='./data/movies_clean.csv', reviews_path='./data/train_data.csv'):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movies_path - (string) file path to the movies, default='./movies_clean.csv'\n",
    "            reviews_path - (string) file path to the reviews, default='./train_data.csv'\n",
    "        \n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            movies - (dataframe) movie dataframe\n",
    "            reviews - (dataframe) review dataframe\n",
    "        '''\n",
    "        \n",
    "        # Read in the datasets\n",
    "        movies = pd.read_csv(movies_path)\n",
    "        reviews = pd.read_csv(reviews_path)\n",
    "       \n",
    "        del movies['Unnamed: 0']\n",
    "        del reviews['Unnamed: 0']\n",
    "        \n",
    "        print('movies')\n",
    "        print(movies.head())\n",
    "        print(movies.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        print('reviews')\n",
    "        print(reviews.head())\n",
    "        print(reviews.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        return movies, reviews\n",
    "        \n",
    "    def create_train_test(self,reviews, order_by, train_size_prct=0.8):\n",
    "        '''    \n",
    "        INPUTS:\n",
    "        ------------\n",
    "            reviews - (pandas df) dataframe to split into train and test\n",
    "            order_by - (string) column name to sort by\n",
    "            train_size_prct - (float) - percentage of data used for training, default=0.8\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            training_df -  (pandas df) dataframe of the training set\n",
    "            validation_df - (pandas df) dataframe of the test set\n",
    "        '''\n",
    "\n",
    "        # Define the train and test data size via train_size_prct\n",
    "        training_size = int(reviews.shape[0] * train_size_prct)\n",
    "        testing_size = reviews.shape[0] - training_size\n",
    "        \n",
    "        # Sort the reviews by date before splitting\n",
    "        # use old data for training, new data for validation\n",
    "        reviews_new = reviews.sort_values(order_by)\n",
    "        training_df = reviews_new.head(training_size)\n",
    "        validation_df = reviews_new.iloc[training_size:training_size+testing_size]\n",
    "\n",
    "        print('reviews_new')\n",
    "        print(reviews_new.head())\n",
    "        print(reviews_new.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        print('training_df')\n",
    "        print(training_df.head())\n",
    "        print(training_df.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        print('validation_df')\n",
    "        print(validation_df.head())\n",
    "        print(validation_df.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "    \n",
    "        return training_df, validation_df\n",
    "\n",
    "    def fit(self,\n",
    "            movies_path='./data/movies_clean.csv', \n",
    "            reviews_path='./data/train_data.csv',\n",
    "            order_by='date',\n",
    "            train_size_prct=0.8,\n",
    "            latent_features=15, \n",
    "            learning_rate=0.005, \n",
    "            iters=10):\n",
    "        \n",
    "        ''' Fit the recommender engine to the dataset and\n",
    "            save the results to pull from when you need to make predictions\n",
    "        \n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movies_path - (string) file path to the movies, default='./movies_clean.csv'\n",
    "            reviews_path - (string) file path to the reviews, default='./train_data.csv'\n",
    "            order_by - (string) column name to sort by\n",
    "            train_size_prct - (float) - percentage of data used for training, default=0.8\n",
    "            latent_features - (int) the number of latent features used, default=15, \n",
    "            learning_rate - (float) the learning rate, default=0.005\n",
    "            iters - (int) the number of iterations, default=10\n",
    "            \n",
    "        OUTPUTS:\n",
    "        -------------\n",
    "            user_mat - (numpy array) a user by latent feature matrix\n",
    "            movie_mat - (numpy array) a latent feature by movie matrix\n",
    "        \n",
    "        '''\n",
    "        # Read in movie and review DataFrames\n",
    "        movies, reviews = self.read_dataset(movies_path,reviews_path)\n",
    "        \n",
    "        # Hyperparameters: Number of latent features, lr, epochs\n",
    "        latent_features = latent_features\n",
    "        learning_rate = learning_rate\n",
    "        iters = iters\n",
    "        \n",
    "        training_df, validation_df = self.create_train_test(reviews, order_by, train_size_prct)\n",
    "        \n",
    "        # Create user-by-item matrix as np array\n",
    "        train_user_item = training_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "        train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "        ratings_mat = np.array(train_data_df)\n",
    "        self.ratings_mat = ratings_mat\n",
    "              \n",
    "        print('user-by-item matrix')\n",
    "        print(ratings_mat)\n",
    "        print(ratings_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        # Number of users and movies in the user-by-item matrix \n",
    "        self.n_users = ratings_mat.shape[0]\n",
    "        self.n_movies = ratings_mat.shape[1]\n",
    "        self.num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "        \n",
    "        print('number of users: ', self.n_users)\n",
    "        print('number of movies: ', self.n_movies)   \n",
    "        print('number of non nan ratings: ', self.num_ratings)      \n",
    "\n",
    "        # Initialize the user and movie matrices with random values\n",
    "        user_mat = np.random.rand(self.n_users, latent_features)\n",
    "        movie_mat = np.random.rand(latent_features, self.n_movies)\n",
    "\n",
    "        print('U matrix (users) before training') \n",
    "        print(user_mat)\n",
    "        print(user_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        print('Vt matrix (movies) before training') \n",
    "        print(movie_mat)\n",
    "        print(movie_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        # Initialize sse at 0 for first iteration\n",
    "        sse_accum = 0\n",
    "\n",
    "        # keep track of iteration and MSE\n",
    "        print(\"Optimizaiton Statistics\")\n",
    "        print(\"Iterations | Mean Squared Error \")\n",
    "\n",
    "        # for each iteration\n",
    "        for iteration in range(iters):\n",
    "\n",
    "            # update our sse\n",
    "            old_sse = sse_accum\n",
    "            sse_accum = 0\n",
    "\n",
    "            # For each user-movie pair\n",
    "            for i in range(self.n_users):\n",
    "                for j in range(self.n_movies):\n",
    "\n",
    "                    # if the rating exists\n",
    "                    if ratings_mat[i, j] > 0:\n",
    "\n",
    "                        # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                        diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "\n",
    "                        # Keep track of the sum of squared errors for the matrix\n",
    "                        sse_accum += diff**2\n",
    "\n",
    "                        # update the values in each matrix in the direction of the gradient\n",
    "                        for k in range(latent_features):\n",
    "                            user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                            movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "                           \n",
    "            # print results\n",
    "            print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / self.num_ratings))\n",
    "            \n",
    "        # Validation\n",
    "        print('Start validation ...')\n",
    "        rmse, perc_rated, actual_v_pred, preds, acts = self.validation_comparison(validation_df, user_mat=user_mat, movie_mat=movie_mat)\n",
    "        print('rmse: ', rmse)\n",
    "        print('perc_rated: ', perc_rated)\n",
    "        print('actual_v_pred: ', actual_v_pred)\n",
    "        \n",
    "        self.plot_validation_results(rmse, perc_rated, actual_v_pred, preds, acts)\n",
    "        \n",
    "        print(' ')\n",
    "        print('Saving user-by-item matrix as pickle ...')\n",
    "        with open('ratings_mat.pkl','wb') as f:\n",
    "            pickle.dump(ratings_mat, f)\n",
    "        print('...done')\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        print(' ')\n",
    "        print('Saving user_mat as pickle ...')\n",
    "        with open('user_mat.pkl','wb') as f:\n",
    "            pickle.dump(user_mat, f)\n",
    "        print('...done')\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "            \n",
    "        print(' ')\n",
    "        print('Saving movie_mat as pickle ...')\n",
    "        with open('movie_mat.pkl','wb') as f:\n",
    "            pickle.dump(movie_mat, f)\n",
    "        print('...done')\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "                  \n",
    "        return user_mat, movie_mat, ratings_mat\n",
    "    \n",
    "    def predict_rating(self, user_matrix, movie_matrix, user_id, movie_id, load_mat=False):\n",
    "        ''' makes predictions of a rating for a user on a movie-user combo\n",
    "        \n",
    "        INPUTS:\n",
    "        ------------\n",
    "            user_matrix - user by latent factor matrix\n",
    "            movie_matrix - latent factor by movie matrix\n",
    "            user_id - the user_id from the reviews df\n",
    "            movie_id - the movie_id according the movies df\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "        '''\n",
    "        if load_mat==True:\n",
    "            ratings_mat, user_mat, movie_mat, ratings_mat = self.load_matrices()\n",
    "\n",
    "        # Create series of users and movies in the right order\n",
    "        user_ids_series = np.array(ratings_mat.index)\n",
    "        movie_ids_series = np.array(ratings_mat.columns)\n",
    "\n",
    "        # User row and Movie Column\n",
    "        user_row = np.where(user_ids_series == user_id)[0][0]\n",
    "        movie_col = np.where(movie_ids_series == movie_id)[0][0]\n",
    "\n",
    "        # Take dot product of that row and column in U and V to make prediction\n",
    "        pred = np.dot(user_matrix[user_row, :], movie_matrix[:, movie_col])\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def validation_comparison(self, val_df, user_mat, movie_mat):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            val_df - the validation dataset created in create_train_test\n",
    "            user_mat - U matrix in FunkSVD\n",
    "            movie_mat - V matrix in FunkSVD\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            rmse - RMSE of how far off each value is from it's predicted value\n",
    "            perc_rated - percent of predictions out of all possible that could be rated\n",
    "            actual_v_pred - a 10 x 10 grid with counts for actual vs predicted values\n",
    "        '''\n",
    "\n",
    "        val_users = np.array(val_df['user_id'])\n",
    "        val_movies = np.array(val_df['movie_id'])\n",
    "        val_ratings = np.array(val_df['rating'])\n",
    "\n",
    "        sse = 0\n",
    "        num_rated = 0\n",
    "        preds, acts = [], []\n",
    "        actual_v_pred = np.zeros((10,10))\n",
    "        print(len(len(val_users)))\n",
    "        for idx in range(len(val_users)):\n",
    "            print(idx)\n",
    "            try:\n",
    "                print('idx not null ', idx)\n",
    "                pred = self.predict_rating(user_mat, movie_mat, val_users[idx], val_movies[idx])\n",
    "                sse += (val_ratings[idx] - pred)**2\n",
    "                num_rated+=1\n",
    "                preds.append(pred)\n",
    "                acts.append(val_ratings[idx])\n",
    "                actual_v_pred[11-int(val_ratings[idx]-1), int(round(pred)-1)]+=1\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        rmse = np.sqrt(sse/num_rated)\n",
    "        perc_rated = num_rated/len(val_users)\n",
    "        return rmse, perc_rated, actual_v_pred, preds, acts\n",
    "    \n",
    "    def plot_validation_results(self, rmse, perc_rated, actual_v_pred, preds, acts):\n",
    "        # How well did we do?\n",
    "        print(rmse, perc_rated)\n",
    "        sns.heatmap(actual_v_pred);\n",
    "        plt.xticks(np.arange(10), np.arange(1,11));\n",
    "        plt.yticks(np.arange(10), np.arange(1,11));\n",
    "        plt.xlabel(\"Predicted Values\");\n",
    "        plt.ylabel(\"Actual Values\");\n",
    "        plt.title(\"Actual vs. Predicted Values\");\n",
    "\n",
    "    def load_matrices(self, ratings_mat_path='ratings_mat.pkl', user_mat_path='user_mat.pkl', movie_mat_path='movie_mat.pkl'):\n",
    "        \n",
    "        with open(ratings_mat_path,'rb') as f:\n",
    "            ratings_mat = pickle.load(f)\n",
    "        print('Shape of user_mat')\n",
    "        print(ratings_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        with open(user_mat_path,'rb') as f:\n",
    "            user_mat = pickle.load(f)\n",
    "        print('Shape of user_mat')\n",
    "        print(user_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        with open(movie_mat_path,'rb') as f:\n",
    "            movie_mat = pickle.load(f)\n",
    "        print('Shape of user_mat')\n",
    "        print(movie_mat.shape)\n",
    "        print('------------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        return ratings_mat, user_mat, movie_mat\n",
    "        \n",
    " \n",
    "    def find_similar_movies(self, movie_id):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movie_id - a movie_id \n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            similar_movies - an array of the most similar movies by title\n",
    "        '''\n",
    "\n",
    "        # find the row of each movie id\n",
    "        movie_idx = np.where(movies['movie_id'] == movie_id)[0][0]\n",
    "\n",
    "        # find the most similar movie indices - to start I said they need to be the same for all content\n",
    "        similar_idxs = np.where(dot_prod_movies[movie_idx] == np.max(dot_prod_movies[movie_idx]))[0]\n",
    "\n",
    "        # pull the movie titles based on the indices\n",
    "        similar_movies = np.array(movies.iloc[similar_idxs, ]['movie'])\n",
    "\n",
    "        return similar_movies\n",
    "    \n",
    "    def get_movie_names(self, movie_ids):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movie_ids - a list of movie_ids\n",
    "\n",
    "        OUTPUT:\n",
    "        ------------\n",
    "            movies - a list of movie names associated with the movie_ids\n",
    "        '''\n",
    "\n",
    "        movie_lst = list(movies[movies['movie_id'].isin(movie_ids)]['movie'])\n",
    "\n",
    "        return movie_lst\n",
    "    \n",
    "   \n",
    "    \n",
    "    def create_ranked_df(self, movies, reviews):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            movies - the movies dataframe\n",
    "            reviews - the reviews dataframe\n",
    "\n",
    "        OUTPUT:\n",
    "        ------------\n",
    "            ranked_movies - a dataframe with movies that are sorted by highest avg rating, more reviews, \n",
    "                        then time, and must have more than 4 ratings\n",
    "        '''\n",
    "\n",
    "        # Pull the average ratings and number of ratings for each movie\n",
    "        movie_ratings = reviews.groupby('movie_id')['rating']\n",
    "        avg_ratings = movie_ratings.mean()\n",
    "        num_ratings = movie_ratings.count()\n",
    "        last_rating = pd.DataFrame(reviews.groupby('movie_id').max()['date'])\n",
    "        last_rating.columns = ['last_rating']\n",
    "\n",
    "        # Add Dates\n",
    "        rating_count_df = pd.DataFrame({'avg_rating': avg_ratings, 'num_ratings': num_ratings})\n",
    "        rating_count_df = rating_count_df.join(last_rating)\n",
    "\n",
    "        # merge with the movies dataset\n",
    "        movie_recs = movies.set_index('movie_id').join(rating_count_df)\n",
    "\n",
    "        # sort by top avg rating and number of ratings\n",
    "        ranked_movies = movie_recs.sort_values(['avg_rating', 'num_ratings', 'last_rating'], ascending=False)\n",
    "\n",
    "        # for edge cases - subset the movie list to those with only 5 or more reviews\n",
    "        ranked_movies = ranked_movies[ranked_movies['num_ratings'] > 4]\n",
    "\n",
    "        return ranked_movies\n",
    "    \n",
    "\n",
    "    def popular_recommendations(self, user_id, n_top, ranked_movies):\n",
    "        '''\n",
    "        INPUT:\n",
    "        ------------\n",
    "            user_id - the user_id (str) of the individual you are making recommendations for\n",
    "            n_top - an integer of the number recommendations you want back\n",
    "            ranked_movies - a pandas dataframe of the already ranked movies based on avg rating, count, and time\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            top_movies - a list of the n_top recommended movies by movie title in order best to worst\n",
    "        '''\n",
    "\n",
    "        top_movies = list(ranked_movies['movie'][:n_top])\n",
    "\n",
    "        return top_movies\n",
    "\n",
    "    \n",
    "        \n",
    "    def start_prediction(self):\n",
    "        user_mat, movie_mat = self.load_matrices()\n",
    "   \n",
    "\n",
    "    def make_recs(self, _id, train_data, train_df, movies, user_mat, _id_type='movie', rec_num=5):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        ------------\n",
    "            _id - either a user or movie id (int)\n",
    "            _id_type - \"movie\" or \"user\" (str)\n",
    "            train_data - dataframe of data as user-movie matrix\n",
    "            train_df - dataframe of training data reviews\n",
    "            movies - movies df\n",
    "            user_mat - the U matrix of matrix factorization\n",
    "            movie_mat - the V matrix of matrix factorization\n",
    "            rec_num - number of recommendations to return (int)\n",
    "\n",
    "        OUTPUTS:\n",
    "        ------------\n",
    "            recs - (array) a list or numpy array of recommended movies like the \n",
    "                    given movie, or recs for a user_id given\n",
    "        '''\n",
    "\n",
    "        # if the user is available from the matrix factorization data, \n",
    "        # I will use this and rank movies based on the predicted values\n",
    "        # For use with user indexing\n",
    "        val_users = train_data_df.index\n",
    "        rec_ids = create_ranked_df(movies, train_df)\n",
    "\n",
    "        if _id_type == 'user':\n",
    "            if _id in train_data.index:\n",
    "                # Get the index of which row the user is in for use in U matrix\n",
    "                idx = np.where(val_users == _id)[0][0]\n",
    "\n",
    "                # take the dot product of that row and the V matrix\n",
    "                preds = np.dot(user_mat[idx,:],movie_mat)\n",
    "\n",
    "                # pull the top movies according to the prediction\n",
    "                indices = preds.argsort()[-rec_num:][::-1] #indices\n",
    "                rec_ids = train_data_df.columns[indices]\n",
    "                rec_names = get_movie_names(rec_ids)\n",
    "\n",
    "            else:\n",
    "                # if we don't have this user, give just top ratings back\n",
    "                rec_names = popular_recommendations(_id, rec_num, ranked_movies)\n",
    "\n",
    "        # Find similar movies if it is a movie that is passed\n",
    "        else:\n",
    "            rec_ids = find_similar_movies(_id)\n",
    "            rec_names = get_movie_names(rec_ids)\n",
    "\n",
    "        return rec_ids, rec_names\n",
    "    \n",
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # test different parts to make sure it works\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies\n",
      "   movie_id                                              movie  \\\n",
      "0         8      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
      "1        10                La sortie des usines Lumi√®re (1895)   \n",
      "2        12                      The Arrival of a Train (1896)   \n",
      "3        25  The Oxford and Cambridge University Boat Race ...   \n",
      "4        91                         Le manoir du diable (1896)   \n",
      "\n",
      "               genre  date  1800's  1900's  2000's  History  News  Horror  \\\n",
      "0  Documentary|Short  1894       1       0       0        0     0       0   \n",
      "1  Documentary|Short  1895       1       0       0        0     0       0   \n",
      "2  Documentary|Short  1896       1       0       0        0     0       0   \n",
      "3                NaN  1895       1       0       0        0     0       0   \n",
      "4       Short|Horror  1896       1       0       0        0     0       1   \n",
      "\n",
      "   ...  Fantasy  Romance  Game-Show  Action  Documentary  Animation  Comedy  \\\n",
      "0  ...        0        0          0       0            1          0       0   \n",
      "1  ...        0        0          0       0            1          0       0   \n",
      "2  ...        0        0          0       0            1          0       0   \n",
      "3  ...        0        0          0       0            0          0       0   \n",
      "4  ...        0        0          0       0            0          0       0   \n",
      "\n",
      "   Short  Western  Thriller  \n",
      "0      1        0         0  \n",
      "1      1        0         0  \n",
      "2      1        0         0  \n",
      "3      0        0         0  \n",
      "4      1        0         0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "(31245, 35)\n",
      "------------------------\n",
      " \n",
      "reviews\n",
      "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
      "0    37287   2171847       6  1362062307  2013-02-28 14:38:27        0   \n",
      "1    33140    444778       8  1362062624  2013-02-28 14:43:44        0   \n",
      "2     6338   1411238       6  1362062838  2013-02-28 14:47:18        0   \n",
      "3    43691   1496422       7  1362063503  2013-02-28 14:58:23        0   \n",
      "4    33799    118799       5  1362063653  2013-02-28 15:00:53        0   \n",
      "\n",
      "   month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
      "0        0        0        0        0  ...        0         0         0   \n",
      "1        0        0        0        0  ...        0         0         0   \n",
      "2        0        0        0        0  ...        0         0         0   \n",
      "3        0        0        0        0  ...        0         0         0   \n",
      "4        0        0        0        0  ...        0         0         0   \n",
      "\n",
      "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
      "0         0          1          0          0          0          0          0  \n",
      "1         0          1          0          0          0          0          0  \n",
      "2         0          1          0          0          0          0          0  \n",
      "3         0          1          0          0          0          0          0  \n",
      "4         0          1          0          0          0          0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(8000, 23)\n",
      "------------------------\n",
      " \n",
      "reviews_new\n",
      "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
      "0    37287   2171847       6  1362062307  2013-02-28 14:38:27        0   \n",
      "1    33140    444778       8  1362062624  2013-02-28 14:43:44        0   \n",
      "2     6338   1411238       6  1362062838  2013-02-28 14:47:18        0   \n",
      "3    43691   1496422       7  1362063503  2013-02-28 14:58:23        0   \n",
      "4    33799    118799       5  1362063653  2013-02-28 15:00:53        0   \n",
      "\n",
      "   month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
      "0        0        0        0        0  ...        0         0         0   \n",
      "1        0        0        0        0  ...        0         0         0   \n",
      "2        0        0        0        0  ...        0         0         0   \n",
      "3        0        0        0        0  ...        0         0         0   \n",
      "4        0        0        0        0  ...        0         0         0   \n",
      "\n",
      "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
      "0         0          1          0          0          0          0          0  \n",
      "1         0          1          0          0          0          0          0  \n",
      "2         0          1          0          0          0          0          0  \n",
      "3         0          1          0          0          0          0          0  \n",
      "4         0          1          0          0          0          0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(8000, 23)\n",
      "------------------------\n",
      " \n",
      "training_df\n",
      "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
      "0    37287   2171847       6  1362062307  2013-02-28 14:38:27        0   \n",
      "1    33140    444778       8  1362062624  2013-02-28 14:43:44        0   \n",
      "2     6338   1411238       6  1362062838  2013-02-28 14:47:18        0   \n",
      "3    43691   1496422       7  1362063503  2013-02-28 14:58:23        0   \n",
      "4    33799    118799       5  1362063653  2013-02-28 15:00:53        0   \n",
      "\n",
      "   month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
      "0        0        0        0        0  ...        0         0         0   \n",
      "1        0        0        0        0  ...        0         0         0   \n",
      "2        0        0        0        0  ...        0         0         0   \n",
      "3        0        0        0        0  ...        0         0         0   \n",
      "4        0        0        0        0  ...        0         0         0   \n",
      "\n",
      "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
      "0         0          1          0          0          0          0          0  \n",
      "1         0          1          0          0          0          0          0  \n",
      "2         0          1          0          0          0          0          0  \n",
      "3         0          1          0          0          0          0          0  \n",
      "4         0          1          0          0          0          0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(6400, 23)\n",
      "------------------------\n",
      " \n",
      "validation_df\n",
      "      user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
      "6400     3687     53221      10  1362968718  2013-03-11 02:25:18        0   \n",
      "6401    40879   1907668       8  1362968736  2013-03-11 02:25:36        0   \n",
      "6402     3687     65126      10  1362968806  2013-03-11 02:26:46        0   \n",
      "6403     3687     52357      10  1362968859  2013-03-11 02:27:39        0   \n",
      "6404      792   2070597       7  1362969029  2013-03-11 02:30:29        0   \n",
      "\n",
      "      month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
      "6400        0        0        0        0  ...        0         0         0   \n",
      "6401        0        0        0        0  ...        0         0         0   \n",
      "6402        0        0        0        0  ...        0         0         0   \n",
      "6403        0        0        0        0  ...        0         0         0   \n",
      "6404        0        0        0        0  ...        0         0         0   \n",
      "\n",
      "      month_12  year_2013  year_2014  year_2015  year_2016  year_2017  \\\n",
      "6400         0          1          0          0          0          0   \n",
      "6401         0          1          0          0          0          0   \n",
      "6402         0          1          0          0          0          0   \n",
      "6403         0          1          0          0          0          0   \n",
      "6404         0          1          0          0          0          0   \n",
      "\n",
      "      year_2018  \n",
      "6400          0  \n",
      "6401          0  \n",
      "6402          0  \n",
      "6403          0  \n",
      "6404          0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(1600, 23)\n",
      "------------------------\n",
      " \n",
      "user-by-item matrix\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "(2832, 2317)\n",
      "------------------------\n",
      " \n",
      "number of users:  2832\n",
      "number of movies:  2317\n",
      "number of non nan ratings:  6400\n",
      "U matrix (users) before training\n",
      "[[0.47552942 0.59387483 0.72583492 ... 0.98239952 0.79411064 0.47049733]\n",
      " [0.73920773 0.66776619 0.2933583  ... 0.31498769 0.93900375 0.32862242]\n",
      " [0.93727815 0.97701263 0.14682661 ... 0.01161701 0.13302291 0.81567745]\n",
      " ...\n",
      " [0.16301024 0.64195224 0.5185452  ... 0.85527696 0.62155732 0.04730873]\n",
      " [0.219694   0.07294665 0.74262572 ... 0.69081385 0.88298046 0.04610694]\n",
      " [0.80732665 0.57959897 0.72167439 ... 0.86865809 0.48469024 0.09456366]]\n",
      "(2832, 15)\n",
      "------------------------\n",
      " \n",
      "Vt matrix (movies) before training\n",
      "[[0.78888278 0.8934686  0.31655442 ... 0.15296438 0.10762828 0.12074359]\n",
      " [0.02840114 0.65882976 0.63358034 ... 0.8833897  0.13608978 0.32201253]\n",
      " [0.1163641  0.92391432 0.18331868 ... 0.64445085 0.75962996 0.96364567]\n",
      " ...\n",
      " [0.5329483  0.86659905 0.56493706 ... 0.66192914 0.6018392  0.99948123]\n",
      " [0.29789003 0.00367232 0.23658834 ... 0.18578276 0.44487858 0.7023356 ]\n",
      " [0.97759331 0.66720647 0.6654937  ... 0.23352386 0.71970776 0.32527064]]\n",
      "(15, 2317)\n",
      "------------------------\n",
      " \n",
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t\t 10.913269\n",
      "2 \t\t 6.209577\n",
      "3 \t\t 4.344460\n",
      "4 \t\t 3.238028\n",
      "5 \t\t 2.506426\n",
      "6 \t\t 1.990199\n",
      "7 \t\t 1.609460\n",
      "8 \t\t 1.319795\n",
      "9 \t\t 1.094379\n",
      "10 \t\t 0.915913\n",
      "11 \t\t 0.772662\n",
      "12 \t\t 0.656358\n",
      "13 \t\t 0.560998\n",
      "14 \t\t 0.482128\n",
      "15 \t\t 0.416381\n",
      "Start validation ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e9c620ed7fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlatent_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         iters=15)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-8e13aaa16b87>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, movies_path, reviews_path, order_by, train_size_prct, latent_features, learning_rate, iters)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start validation ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_rated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_v_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmovie_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rmse: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'perc_rated: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_rated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8e13aaa16b87>\u001b[0m in \u001b[0;36mvalidation_comparison\u001b[0;34m(self, val_df, user_mat, movie_mat)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mactual_v_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "rec = Recommender()\n",
    "rec.fit(movies_path='./data/movies_clean.csv', \n",
    "        reviews_path='./data/train_data.csv',\n",
    "        order_by='date',\n",
    "        train_size_prct=0.8,\n",
    "        latent_features=15, \n",
    "        learning_rate=0.005, \n",
    "        iters=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_recommendations(48, 'user')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
